---
title: "Reproducible Research - Peer Assessment2"
author: "robertwcw"
date: "9/21/2020"
output: 
  html_document: 
    fig_caption: yes
    keep_md: yes
---
## SYNOPSIS

Natural disaster triggered by storms and abnormal weather phenomenons may lead to public health issues and dire economic consequences. The extent, severity, and impact of injuries/fatalities and economic losses are largely determined by the amount of energy unleashed by the types of events in the weather related disasters. This data analysis attempts to address the concerns **WHERE** the events took place and **WHEN** the disasters struck by **WHAT** types of events give rise to deleterious social impact aftermath with respect to economic and public health. Base on the US National Oceanic and Atmospheric Administration (NOAA) storm database, this project makes use of relevant metrics of the number of human injuries/fatalities, financial losses in properties/crops damages in relation to events types across the US from year 1950 to year 2011.  
&nbsp;

#### Set up R workspace environment
```{r setup, message=TRUE, resuts="hide"}
knitr::opts_chunk$set(echo = TRUE)
Sys.setenv(TZ = "UTC")      # set global TZ to UTC for POSIXt class

.Rfliburl <- "https://raw.githubusercontent.com/robertwcw/Rflib/master"
source(file.path(.Rfliburl,"getRflib.R"),local = TRUE)
source(getRflib("is.defined.R"),local = TRUE)
source(getRflib("strCap.R"),local = TRUE)
# source(getRflib("myplclust.R"),local = TRUE)

library(data.table)
# library(lubridate)
library(dplyr)
library(maps)
# library(xts)

# 'udf.num2gcs' user-defined function to convert LATITUDE & LONGITUDE coordinate values in integer type to nnn.dddd geographic coordinate system format 
udf.num2gcs <- function(X, y) { # y is number of significant digits.
        if (!is.na(X) & !is.null(X) & is.numeric(X)) {
                x <- as.character(X)
                l <- nchar(x)
                ifelse(l < 3, return(as.numeric(x)),
                       ifelse(l == 3, y <- 1,
                              ifelse(l == 4, y <- 2,
                                     ifelse(l > 4, y <- y, y <- 0))))
                y <- l - y
                X <- as.numeric(paste0(x,"e",-y))
        }
        return(X)
}

# 'udf.stripsign' user-defined function to strip -ve sign from numeric value
udf.stripsign <- function(x) {
        if (!is.na(x) & !is.null(x) & is.numeric(x)) {
                x <- x * sign(x)
        }
        return(x)
}

# 'udf.prependsign' user-defined function to prepend -ve sign to numeric value
udf.prependsign <- function(x) {
        if (!is.na(x) & !is.null(x) & is.numeric(x)) {
                x <- x * sign(-x)
        }
        return(x)
}

# 'udf.str2time' user-defined function to put TIME string into proper format
udf.str2time <- function(x) {
        l <- nchar(x)
        x <- case_when(
                l %in% c(3,4) ~ {
                        z <- substr(strptime(sprintf("%04s", x), "%H%M"), 12, 19)
                        ifelse(is.na(z) | z == "", 
                               "00:00:00",
                               substr(strptime(sprintf("%04s", x), "%H%M"), 12, 19))
                },
                l == 11 ~ {
                        z <- substr(strptime(x, "%I:%M:%S %p"), 12, 19)
                        ifelse(is.na(z),
                               substr(strptime(x, "%H:%M:%S"), 12, 19),
                               ifelse(z == "",
                                      substr(strptime(x, "%H:%M:%S %p"), 12, 19),
                                      z))
                },
                TRUE ~ x
        )
        return(x) 
}
```
&nbsp;

#### Data Loading

Loading *raw* comma-delimited text file data set downloaded from course website into R workspace as data.table class object with naming of the data object derives from website data source programmatically, by-passing manual data staging as much as possible during loading phase.

```{r data.load, cache=TRUE, resuts="hide"}
# loading data downloaded from course website into R workspace 

# set data source url to course website
fileurl <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
datadir <- paste(".", "data", sep = "/")
filetmp <- tempfile()
filenam <- character()

download.file(fileurl, filetmp)

if (!dir.exists(datadir)) {
        dir.create(datadir)
}

# extract source data file name as name of work data object in workspace 
filels <- strsplit(basename(fileurl), "%2F", fixed = TRUE)[[1]]
for (i in 1:length(filels)) {
        filein <- strsplit(filels[i], ".", fixed = TRUE)[[1]]
        if (length(filein) > 1) {
                filenam[i] <- filein[1]
                filesrc <- bzfile(filetmp, open = "r")
                assign(filenam[i], data.table(read.csv(filesrc)))
                flush(filesrc)
        }
}
close(filesrc)

filenam <- filenam[which(!is.na(filenam))]

# # save an archive copy of StormData data.table to local `r datadir`
# for (i in 1:length(filenam)) {
#         fileout <- paste(datadir, filenam[i], sep = "/")
#         fileout <- paste(fileout, "csv", "bz2", sep = ".")
#         filesrc <- bzfile(fileout, open = "w")
#         write.csv(get(filenam[i]), filesrc, row.names = FALSE)
#         flush(filesrc)
# }
# close(filesrc)
# rm(fileout)

unlink(filetmp)
rm(fileurl,filetmp,filesrc,filels,filein)
```
&nbsp;

#### Exploratory Data Analysis

```{r eda.0}
for (i in 1:length(filenam)) {
        print(paste(i, ":",filenam[i], "(",floor(object.size(get(filenam[i]))/10e+05),"MB)"))
}
rm(i)
```
**`r length(filenam)`** *raw* data `r ifelse(length(filenam) > 1, "sets were", "set was")` loaded into R workspace from NOAA sourced data downloaded from the course website. (number in bracket depicts memory footprint).

Structure of data object **`r filenam[1]`**.
```{r eda.1}
str(get(filenam[1]))
```
**`r length(names(get(filenam[1])))`** columns found in the *raw* data set **`r filenam[1]`**. 

<!-- For this data analysis work, we shall create a working data set called **stormdata** consisting 18 data columns grabbed from the *raw* data set **`r filenam[1]`**. (see attached list) -->

```{r data.proc, results = "hide"}
# column number of the selected variable
v <- c(1,2,3,4,5,6,7,8,12,13,19,20,21,22,23,24,25,26,27,28,32,33,34,35,37)
names(get(filenam[1]))[v]


# HYPOTHESIS: an event began on BGN_DATE at BGN_TIME in one county and is said to end on END_DATE equates BGN_DATE at END_TIME in same county when END_DATE is empty but END_TIME is not. {END_DATE == "" & END_TIME != ""} 

# HYPOTHESIS: an event began on BGN_DATE at BGN_TIME in one county and is said to be ended on END_DATE at END_TIME equates 23:59:59 (postulated) in same county when END_DATE is not empty but END_TIME contains empty value, though the event may continued on to neighbouring county. {END_DATE != "" & END_TIME == ""} 

# HYPOTHESIS: {END_DATE == "" & END_TIME == ""} an event began on BGN_DATE at BGN_TIME in one county and is said to be ended in same county on END_DATE equates BGN_DATE at END_TIME equates 23:59:59 when END_DATE and END_TIME both contain empty values, though the event may continued on to neighbouring county at the cut-over time at 00:00:00 next-day.

# HYPOTHESIS: an event began on BGN_DATE at BGN_TIME in one county and is said to be ended in the same county on END_DATE at END_TIME. {END_DATE != "" & END_TIME != ""} 

#    user  system elapsed 
# 583.327 108.792 695.236 
d1 <- sub(" .*", "", StormData$BGN_DATE)
d2 <- gsub("[oO]", "0", StormData$BGN_TIME) # rectify typo error of 'O' for '0'
d2 <- sub("12:00:00 AM", "00:00:00", d2) # rectify non-POSIXt compliant time fmt
d2 <- sub("00:00:00 AM", "00:00:00", d2) # rectify non-POSIXt compliant time fmt
d2 <- unlist(lapply(d2, udf.str2time)) # unify various time format to "hh:mm:ss"

StormData <- StormData %>% mutate(EV_TIMESTAMP = as.POSIXct(strptime(paste(d1,d2), "%m/%d/%Y %H:%M:%S")))

rm(d1,d2)

# # # NOT USED
# # prepend -ve sign to LONGITUDE values belong to the western hemisphere
#   StormData$LONGITUDE <- sapply(StormData$LONGITUDE, udf.prependsign)

# reformat LATITUDE to geographic coordinate system format nnn.ddd
  numsign <- sign(StormData$LATITUDE)
  lat <- sapply(StormData$LATITUDE, udf.stripsign)
  lat <- sapply(lat, udf.num2gcs, 2) # param '2' is number of significant digits
  StormData$LATITUDE <- lat * (numsign * numsign) # LATs belong to northern hemisphere 
  
# reformat LONGITUDE to geographic coordinate system format nnn.ddd
  numsign <- sign(StormData$LONGITUDE)
  lon <- sapply(StormData$LONGITUDE, udf.stripsign)
  lon <- sapply(lon, udf.num2gcs, 3) # param '3' is number of significant digits
  StormData$LONGITUDE <- lon * (numsign * -numsign) # LONs belong to western hemisphere
```


```{r house.keeping}
# detach("package:xts", unload = TRUE)
detach("package:dplyr", unload = TRUE)
detach("package:data.table", unload = TRUE)
```
